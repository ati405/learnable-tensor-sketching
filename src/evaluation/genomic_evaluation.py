#!/usr/bin/env python3
"""
Genomic Dataset Evaluation Framework
Phase 4 Evaluation: Large-scale biological validation and applications
"""

import torch
import torch.nn.functional as F
import numpy as np
import pandas as pd
import os
import sys
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from collections import defaultdict
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import roc_auc_score, precision_recall_curve, auc
from sklearn.model_selection import train_test_split
import joblib

# Import tensor sketching implementations
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'baseline'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'learnable'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'advanced'))

from pytorch_tensor_sketch import TensorSketchBaseline
from clean_differentiable_sketch import CleanDifferentiableTensorSketch
from unified_advanced_sketch import AdvancedTensorSketchingSystem

@dataclass
class GenomicResult:
    """Data structure for genomic evaluation results."""
    method: str
    dataset: str
    task: str
    accuracy: float
    auc_roc: float
    auc_pr: float
    precision: float
    recall: float
    f1_score: float
    biological_relevance: float
    computation_time: float

class SequenceEncoder:
    """Encode DNA sequences to numerical format."""
    
    def __init__(self):
        self.nucleotide_map = {'A': 0, 'T': 1, 'G': 2, 'C': 3, 'N': 0}  # N maps to A as default
    
    def encode_sequence(self, sequence: str) -> torch.Tensor:
        """
        Encode DNA sequence to tensor.
        
        Args:
            sequence: DNA sequence string
            
        Returns:
            Encoded sequence tensor
        """
        sequence = sequence.upper()
        encoded = []
        
        for nucleotide in sequence:
            if nucleotide in self.nucleotide_map:
                encoded.append(self.nucleotide_map[nucleotide])
            else:
                encoded.append(0)  # Default to A for unknown nucleotides
        
        return torch.tensor(encoded, dtype=torch.long)
    
    def batch_encode(self, sequences: List[str]) -> List[torch.Tensor]:
        """Encode multiple sequences."""
        return [self.encode_sequence(seq) for seq in sequences]

class HGMDDatasetLoader:
    """Load and process HGMD dataset for genomic evaluation."""
    
    def __init__(self, dataset_path: str):
        self.dataset_path = dataset_path
        self.encoder = SequenceEncoder()
    
    def load_variant_data(self) -> Tuple[List[str], List[int]]:
        """
        Load HGMD variant data.
        
        Returns:
            Tuple of (sequences, labels) where labels indicate pathogenicity
        """
        # Check if dataset exists
        if not os.path.exists(self.dataset_path):
            print(f"Dataset not found at {self.dataset_path}")
            print("Generating synthetic genomic data for demonstration...")
            return self._generate_synthetic_genomic_data()
        
        try:
            # Try to load real HGMD data
            return self._load_real_hgmd_data()
        except Exception as e:
            print(f"Error loading HGMD data: {e}")
            print("Generating synthetic genomic data for demonstration...")
            return self._generate_synthetic_genomic_data()
    
    def _load_real_hgmd_data(self) -> Tuple[List[str], List[int]]:
        """Load actual HGMD dataset if available."""
        # Implementation would depend on actual HGMD data format
        # This is a placeholder for real data loading
        
        sequences = []
        labels = []
        
        # Example CSV loading (adjust based on actual format)
        try:
            df = pd.read_csv(self.dataset_path)
            if 'sequence' in df.columns and 'pathogenic' in df.columns:
                sequences = df['sequence'].tolist()
                labels = df['pathogenic'].tolist()
            else:
                raise ValueError("Expected columns 'sequence' and 'pathogenic' not found")
        except Exception as e:
            raise e
        
        return sequences, labels
    
    def _generate_synthetic_genomic_data(self) -> Tuple[List[str], List[int]]:
        """Generate synthetic genomic data for evaluation."""
        np.random.seed(42)
        
        sequences = []
        labels = []
        
        # Generate pathogenic variants (label = 1)
        pathogenic_patterns = [
            # Known pathogenic patterns
            'ATGGCC',  # Common mutation site
            'CGGCTA',  # CpG methylation site
            'TGGCCA',  # Regulatory sequence
            'GCCAAT',  # Transcription factor binding
            'AACCGG',  # Splice site variant
        ]
        
        for _ in range(500):  # 500 pathogenic sequences
            base_pattern = np.random.choice(pathogenic_patterns)
            # Add random flanking sequences
            left_flank = ''.join(np.random.choice(['A', 'T', 'G', 'C'], size=np.random.randint(10, 30)))
            right_flank = ''.join(np.random.choice(['A', 'T', 'G', 'C'], size=np.random.randint(10, 30)))
            
            sequence = left_flank + base_pattern + right_flank
            sequences.append(sequence)
            labels.append(1)  # Pathogenic
        
        # Generate benign variants (label = 0)
        for _ in range(500):  # 500 benign sequences
            # Random sequences without pathogenic patterns
            length = np.random.randint(20, 60)
            sequence = ''.join(np.random.choice(['A', 'T', 'G', 'C'], size=length))
            
            # Ensure it doesn't contain pathogenic patterns
            contains_pathogenic = any(pattern in sequence for pattern in pathogenic_patterns)
            if not contains_pathogenic:
                sequences.append(sequence)
                labels.append(0)  # Benign
        
        print(f"Generated {len(sequences)} synthetic genomic sequences")
        print(f"Pathogenic: {sum(labels)}, Benign: {len(labels) - sum(labels)}")
        
        return sequences, labels

class GenomicEvaluator:
    """
    Comprehensive genomic evaluation framework.
    
    Evaluates tensor sketching methods on:
    1. Variant pathogenicity prediction
    2. Sequence similarity and homology detection
    3. Functional sequence classification
    4. Large-scale genomic pattern recognition
    """
    
    def __init__(self, 
                 sketch_dim: int = 64,
                 device: str = 'cpu',
                 seed: int = 42):
        """
        Initialize genomic evaluator.
        
        Args:
            sketch_dim: Dimension for tensor sketches
            device: PyTorch device
            seed: Random seed
        """
        self.sketch_dim = sketch_dim
        self.device = device
        self.seed = seed
        
        torch.manual_seed(seed)
        np.random.seed(seed)
        
        # Initialize tensor sketching methods
        self.methods = self._initialize_methods()
        self.encoder = SequenceEncoder()
        
        # Results storage
        self.genomic_results = []
    
    def _initialize_methods(self) -> Dict[str, Any]:
        """Initialize all tensor sketching methods."""
        methods = {}
        
        # Baseline method
        methods['baseline'] = TensorSketchBaseline(
            alphabet_size=4,
            sketch_dim=self.sketch_dim,
            subsequence_len=3,
            device=self.device
        )
        
        # Phase 2: Learnable method
        methods['phase2_learnable'] = CleanDifferentiableTensorSketch(
            alphabet_size=4,
            sketch_dim=self.sketch_dim,
            subsequence_len=3,
            device=self.device,
            use_soft_hash=True
        )
        
        # Phase 3: Advanced system
        methods['phase3_advanced'] = AdvancedTensorSketchingSystem(
            alphabet_size=4,
            base_sketch_dim=self.sketch_dim,
            subsequence_len=3,
            device=self.device,
            use_multi_resolution=True,
            use_graph_awareness=True,
            use_attention=True,
            use_adaptive_dimension=True
        )
        
        return methods
    
    def evaluate_variant_pathogenicity(self, 
                                     sequences: List[str], 
                                     labels: List[int]) -> Dict[str, Dict[str, float]]:
        """
        Evaluate methods on variant pathogenicity prediction task.
        
        Args:
            sequences: List of DNA sequences
            labels: List of pathogenicity labels (0=benign, 1=pathogenic)
            
        Returns:
            Dictionary of evaluation metrics for each method
        """
        print("Evaluating Variant Pathogenicity Prediction...")
        
        # Encode sequences
        encoded_sequences = self.encoder.batch_encode(sequences)
        
        # Filter out sequences that are too short
        min_length = 5
        filtered_data = [(seq, encoded, label) for seq, encoded, label in 
                        zip(sequences, encoded_sequences, labels) 
                        if len(encoded) >= min_length]
        
        if len(filtered_data) < 10:
            print("Not enough valid sequences for evaluation")
            return {}
        
        sequences, encoded_sequences, labels = zip(*filtered_data)
        
        results = {}
        
        for method_name, method in self.methods.items():
            print(f"  Evaluating {method_name}...")
            
            try:
                # Compute sketches for all sequences
                sketches = []
                for encoded_seq in encoded_sequences:
                    if hasattr(method, '__call__'):
                        sketch = method(encoded_seq)
                    else:
                        sketch = method.forward(encoded_seq)
                    sketches.append(sketch.detach().numpy())
                
                sketches = np.array(sketches)
                
                # Split data for evaluation
                X_train, X_test, y_train, y_test = train_test_split(
                    sketches, labels, test_size=0.3, random_state=self.seed, stratify=labels
                )
                
                # Train simple classifier on sketches
                from sklearn.ensemble import RandomForestClassifier
                clf = RandomForestClassifier(n_estimators=100, random_state=self.seed)
                clf.fit(X_train, y_train)
                
                # Evaluate
                y_pred = clf.predict(X_test)
                y_pred_proba = clf.predict_proba(X_test)[:, 1]
                
                # Compute metrics
                accuracy = np.mean(y_pred == y_test)
                auc_roc = roc_auc_score(y_test, y_pred_proba)
                
                precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)
                auc_pr = auc(recall, precision)
                
                # Compute F1 score
                tp = np.sum((y_pred == 1) & (y_test == 1))
                fp = np.sum((y_pred == 1) & (y_test == 0))
                fn = np.sum((y_pred == 0) & (y_test == 1))
                
                precision_score = tp / (tp + fp) if (tp + fp) > 0 else 0
                recall_score = tp / (tp + fn) if (tp + fn) > 0 else 0
                f1 = 2 * precision_score * recall_score / (precision_score + recall_score) if (precision_score + recall_score) > 0 else 0
                
                results[method_name] = {
                    'accuracy': accuracy,
                    'auc_roc': auc_roc,
                    'auc_pr': auc_pr,
                    'precision': precision_score,
                    'recall': recall_score,
                    'f1_score': f1,
                    'num_samples': len(y_test)
                }
                
                print(f"    âœ“ Accuracy: {accuracy:.3f}, AUC-ROC: {auc_roc:.3f}, F1: {f1:.3f}")
                
            except Exception as e:
                print(f"    âœ— Error: {e}")
                results[method_name] = {
                    'accuracy': 0.0,
                    'auc_roc': 0.5,
                    'auc_pr': 0.5,
                    'precision': 0.0,
                    'recall': 0.0,
                    'f1_score': 0.0,
                    'num_samples': 0
                }
        
        return results
    
    def evaluate_sequence_similarity(self, sequences: List[str]) -> Dict[str, Dict[str, float]]:
        """
        Evaluate methods on sequence similarity detection.
        
        Args:
            sequences: List of DNA sequences
            
        Returns:
            Dictionary of similarity evaluation metrics
        """
        print("Evaluating Sequence Similarity Detection...")
        
        # Encode sequences
        encoded_sequences = self.encoder.batch_encode(sequences)
        
        # Filter valid sequences
        min_length = 5
        valid_sequences = [(seq, encoded) for seq, encoded in zip(sequences, encoded_sequences) 
                          if len(encoded) >= min_length]
        
        if len(valid_sequences) < 4:
            print("Not enough sequences for similarity evaluation")
            return {}
        
        sequences, encoded_sequences = zip(*valid_sequences)
        
        results = {}
        
        for method_name, method in self.methods.items():
            print(f"  Evaluating {method_name}...")
            
            try:
                # Compute sketches
                sketches = []
                for encoded_seq in encoded_sequences:
                    if hasattr(method, '__call__'):
                        sketch = method(encoded_seq)
                    else:
                        sketch = method.forward(encoded_seq)
                    sketches.append(sketch)
                
                # Compute pairwise similarities
                similarities = []
                true_similarities = []
                
                for i in range(len(sketches)):
                    for j in range(i + 1, len(sketches)):
                        # Sketch-based similarity
                        sketch_sim = F.cosine_similarity(sketches[i], sketches[j], dim=0).item()
                        similarities.append(sketch_sim)
                        
                        # True sequence similarity (edit distance based)
                        true_sim = self._compute_sequence_similarity(sequences[i], sequences[j])
                        true_similarities.append(true_sim)
                
                # Compute correlation between sketch and true similarities
                correlation = np.corrcoef(similarities, true_similarities)[0, 1]
                if np.isnan(correlation):
                    correlation = 0.0
                
                # Compute other metrics
                avg_similarity = np.mean(similarities)
                similarity_variance = np.var(similarities)
                
                results[method_name] = {
                    'similarity_correlation': correlation,
                    'avg_similarity': avg_similarity,
                    'similarity_variance': similarity_variance,
                    'num_comparisons': len(similarities)
                }
                
                print(f"    âœ“ Correlation: {correlation:.3f}, Avg similarity: {avg_similarity:.3f}")
                
            except Exception as e:
                print(f"    âœ— Error: {e}")
                results[method_name] = {
                    'similarity_correlation': 0.0,
                    'avg_similarity': 0.0,
                    'similarity_variance': 0.0,
                    'num_comparisons': 0
                }
        
        return results
    
    def _compute_sequence_similarity(self, seq1: str, seq2: str) -> float:
        """
        Compute true sequence similarity using edit distance.
        
        Args:
            seq1: First sequence
            seq2: Second sequence
            
        Returns:
            Normalized similarity score [0, 1]
        """
        # Simple edit distance implementation
        m, n = len(seq1), len(seq2)
        
        # Create DP table
        dp = [[0] * (n + 1) for _ in range(m + 1)]
        
        # Initialize base cases
        for i in range(m + 1):
            dp[i][0] = i
        for j in range(n + 1):
            dp[0][j] = j
        
        # Fill DP table
        for i in range(1, m + 1):
            for j in range(1, n + 1):
                if seq1[i-1] == seq2[j-1]:
                    dp[i][j] = dp[i-1][j-1]
                else:
                    dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])
        
        edit_distance = dp[m][n]
        max_length = max(m, n)
        
        # Convert to similarity (higher is more similar)
        similarity = 1.0 - (edit_distance / max_length) if max_length > 0 else 1.0
        return max(0.0, similarity)
    
    def evaluate_biological_relevance(self, sequences: List[str], labels: List[int]) -> Dict[str, float]:
        """
        Evaluate biological relevance of sketching methods.
        
        Args:
            sequences: List of DNA sequences
            labels: Associated biological labels
            
        Returns:
            Dictionary of biological relevance scores
        """
        print("Evaluating Biological Relevance...")
        
        encoded_sequences = self.encoder.batch_encode(sequences)
        
        # Filter valid sequences
        valid_data = [(seq, encoded, label) for seq, encoded, label in 
                     zip(sequences, encoded_sequences, labels) 
                     if len(encoded) >= 5]
        
        if len(valid_data) < 10:
            return {}
        
        sequences, encoded_sequences, labels = zip(*valid_data)
        
        relevance_scores = {}
        
        for method_name, method in self.methods.items():
            try:
                # Compute sketches
                sketches = []
                for encoded_seq in encoded_sequences:
                    if hasattr(method, '__call__'):
                        sketch = method(encoded_seq)
                    else:
                        sketch = method.forward(encoded_seq)
                    sketches.append(sketch.detach().numpy())
                
                # Compute biological relevance as ability to separate classes
                from sklearn.metrics import silhouette_score
                if len(set(labels)) > 1:
                    relevance = silhouette_score(sketches, labels)
                else:
                    relevance = 0.0
                
                relevance_scores[method_name] = max(0.0, relevance)
                
            except Exception as e:
                print(f"Error computing biological relevance for {method_name}: {e}")
                relevance_scores[method_name] = 0.0
        
        return relevance_scores
    
    def run_comprehensive_genomic_evaluation(self, dataset_path: str) -> pd.DataFrame:
        """
        Run comprehensive genomic evaluation.
        
        Args:
            dataset_path: Path to genomic dataset
            
        Returns:
            DataFrame with evaluation results
        """
        print("ðŸ§¬ Starting Comprehensive Genomic Evaluation")
        print("=" * 60)
        
        # Load genomic data
        loader = HGMDDatasetLoader(dataset_path)
        sequences, labels = loader.load_variant_data()
        
        if not sequences:
            print("No genomic data available for evaluation")
            return pd.DataFrame()
        
        print(f"Loaded {len(sequences)} genomic sequences")
        
        all_results = []
        
        # 1. Variant pathogenicity prediction
        pathogenicity_results = self.evaluate_variant_pathogenicity(sequences, labels)
        for method, metrics in pathogenicity_results.items():
            result = {
                'method': method,
                'task': 'pathogenicity_prediction',
                'accuracy': metrics['accuracy'],
                'auc_roc': metrics['auc_roc'],
                'auc_pr': metrics['auc_pr'],
                'f1_score': metrics['f1_score'],
                'num_samples': metrics['num_samples']
            }
            all_results.append(result)
        
        # 2. Sequence similarity evaluation
        similarity_results = self.evaluate_sequence_similarity(sequences[:50])  # Use subset for speed
        for method, metrics in similarity_results.items():
            result = {
                'method': method,
                'task': 'sequence_similarity',
                'similarity_correlation': metrics['similarity_correlation'],
                'avg_similarity': metrics['avg_similarity'],
                'num_comparisons': metrics['num_comparisons']
            }
            all_results.append(result)
        
        # 3. Biological relevance
        biological_scores = self.evaluate_biological_relevance(sequences, labels)
        for method, score in biological_scores.items():
            result = {
                'method': method,
                'task': 'biological_relevance',
                'biological_relevance_score': score
            }
            all_results.append(result)
        
        # Convert to DataFrame
        results_df = pd.DataFrame(all_results)
        
        return results_df
    
    def generate_genomic_plots(self, results_df: pd.DataFrame, output_dir: str = './genomic_results'):
        """Generate genomic evaluation plots."""
        os.makedirs(output_dir, exist_ok=True)
        
        plt.style.use('seaborn-v0_8')
        
        # Plot pathogenicity prediction results
        pathogenicity_data = results_df[results_df['task'] == 'pathogenicity_prediction']
        if not pathogenicity_data.empty:
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # Accuracy
            sns.barplot(data=pathogenicity_data, x='method', y='accuracy', ax=axes[0])
            axes[0].set_title('Pathogenicity Prediction Accuracy')
            axes[0].tick_params(axis='x', rotation=45)
            
            # AUC-ROC
            sns.barplot(data=pathogenicity_data, x='method', y='auc_roc', ax=axes[1])
            axes[1].set_title('AUC-ROC Score')
            axes[1].tick_params(axis='x', rotation=45)
            
            # F1 Score
            sns.barplot(data=pathogenicity_data, x='method', y='f1_score', ax=axes[2])
            axes[2].set_title('F1 Score')
            axes[2].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            plt.savefig(f'{output_dir}/pathogenicity_results.png', dpi=300, bbox_inches='tight')
            plt.close()
        
        print(f"Genomic evaluation plots saved to {output_dir}/")

def run_genomic_evaluation():
    """Run the complete genomic evaluation."""
    print("ðŸ§¬ Starting Genomic Evaluation Framework")
    
    # Initialize evaluator
    evaluator = GenomicEvaluator(sketch_dim=32, seed=42)
    
    # Path to HGMD dataset (will use synthetic data if not found)
    dataset_path = "/Users/atefehjoudaki/Desktop/hgmd_2025_2/amir_paper/dataset"
    
    # Run comprehensive evaluation
    results_df = evaluator.run_comprehensive_genomic_evaluation(dataset_path)
    
    if results_df.empty:
        print("No evaluation results generated")
        return
    
    # Generate plots
    evaluator.generate_genomic_plots(results_df)
    
    # Save results
    results_df.to_csv('./genomic_results/genomic_evaluation_results.csv', index=False)
    
    # Print summary
    print("\n" + "=" * 60)
    print("ðŸ§¬ GENOMIC EVALUATION SUMMARY")
    print("=" * 60)
    
    # Pathogenicity prediction summary
    pathogenicity_data = results_df[results_df['task'] == 'pathogenicity_prediction']
    if not pathogenicity_data.empty:
        print("\nðŸ“Š Pathogenicity Prediction Results:")
        for _, row in pathogenicity_data.iterrows():
            print(f"  {row['method']}: Accuracy={row['accuracy']:.3f}, AUC-ROC={row['auc_roc']:.3f}, F1={row['f1_score']:.3f}")
    
    # Similarity correlation summary
    similarity_data = results_df[results_df['task'] == 'sequence_similarity']
    if not similarity_data.empty:
        print("\nðŸ”— Sequence Similarity Results:")
        for _, row in similarity_data.iterrows():
            print(f"  {row['method']}: Correlation={row['similarity_correlation']:.3f}")
    
    # Biological relevance summary
    biological_data = results_df[results_df['task'] == 'biological_relevance']
    if not biological_data.empty:
        print("\nðŸ§¬ Biological Relevance Results:")
        for _, row in biological_data.iterrows():
            print(f"  {row['method']}: Relevance={row['biological_relevance_score']:.3f}")
    
    print("\nâœ… Genomic evaluation completed successfully!")
    
    return results_df

if __name__ == "__main__":
    results = run_genomic_evaluation()